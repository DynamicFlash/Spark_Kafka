{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2b30669b-94f0-4506-9958-0db4656e5c6e","showTitle":false,"title":""}},"source":["#Spark Structured Streaming using Kafka and SASL_SSL and SCRAM-SHA-256"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9bb7cee0-585f-472d-8214-2b28e7cc048c","showTitle":false,"title":""}},"source":["The consumer and producer implemented using referance Confluent Kafka library and CloudKarafka cluster:\n","<ol>\n","  <li>Create jass file for connecting to Kafka cluster</li>\n","  <li>Setup Databricks for remote kafka authentication</li>\n","  <li>Authenticate to Karafka cluster using Spark</li>\n","  <li>View Structured Stream in Databricks</li> \n","</ol>"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d3992a79-eb34-49e5-86e9-a074628726ad","showTitle":false,"title":""}},"source":["#Configuration parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8b2d35d8-7954-4ca8-ae4e-9f8792ca65c8","showTitle":false,"title":""}},"outputs":[],"source":["#UseKafkaBrokersFollowedByCommas\n","CLOUDKARAFKA_BROKERS = 'Broker1:port,Broker2:port,Broker3:port'\n","\n","#Kafka topic to consume from\n","CLOUDKARAFKA_TOPIC = \"KafkaTopic\" #usually looks like CLOUDKARAFKA_USERNAME-default or CLOUDKARAFKA_USERNAME-anything_you_used_during_setup\n","\n","#Kafka Partition for consuming the topic\n","CLOUDKARAFKA_TOPIC_PARTITION = 0"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"81c42a26-f8d0-4da4-a17a-0d35097cdbcb","showTitle":false,"title":""}},"source":["###Create config to be used by the Kafka client class"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"675ab04d-b336-4450-8b65-ecc7663e6ce6","showTitle":false,"title":""}},"source":["###Create JAAS file to be used to connect with secure kafka cluster(karafka)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3ca6cae8-a0e3-4a8c-adf1-802c2e257b69","showTitle":false,"title":""}},"source":["Define Kafka client\n","<ol>\n","  <li>We are going to use Scram login module as it is used by Karafka brokers as mentioned by their website \"org.apache.kafka.common.security.scram.ScramLoginModule\"</li>\n","  <li>Debug is set to true so we can see the attributes used to create the consumer(use logging level as \"INFO\")</li>\n","  <li>Username is as mentioned in your karafka dashboard</li>\n","  <li>Password is as mentioned in your karafka dashboard</li> \n","</ol>"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5541dd37-9ed7-429a-afd4-6febf390feb1","showTitle":false,"title":""}},"source":["update username and password accordingly"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"78214860-a866-4851-9ed3-3430194f6858","showTitle":false,"title":""}},"outputs":[],"source":["kafka_conf = \"\"\"\n","            KafkaClient {\n","            org.apache.kafka.common.security.scram.ScramLoginModule required\n","            debug=true\n","            username=\"karafka_username\"\n","            password=\"karafka_password\";\n","            };\n","             \"\"\""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f20323a3-952d-4b09-aa6a-0562fc4c80fa","showTitle":false,"title":""}},"source":["Write the file to disk, it will be used to set configuration later"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2bc7cbe3-665b-4295-80f4-558ad2b95993","showTitle":false,"title":""}},"outputs":[],"source":["with open('/databricks/driver/kafka_jaas.conf', 'w+') as fp:\n","    fp.write(kafka_conf)\n","    fp.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"38d2f8a3-cb5d-436e-8a8a-90cd636e0f7b","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Out[96]: ['conf',\n"," 'preload_class.lst',\n"," 'eventlogs',\n"," 'kafka_conf.conf',\n"," 'metastore_db',\n"," 'kafka_jaas.conf',\n"," 'logs',\n"," 'ganglia']"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Out[96]: ['conf',\n 'preload_class.lst',\n 'eventlogs',\n 'kafka_conf.conf',\n 'metastore_db',\n 'kafka_jaas.conf',\n 'logs',\n 'ganglia']","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["import os\n","\n","os.listdir('/databricks/driver/')"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"31d22a9d-78fc-49ad-a019-d87db15a408d","showTitle":false,"title":""}},"source":["####Configuration of consumer so as to connect to Kafka cluster"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b3581538-61f3-46d9-a162-7166d7f02c3e","showTitle":false,"title":""}},"source":["All parameters you can work with in kafka client\n","<br>Link : https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n","<br>\n","<ol>\n","  <li><b>'bootstrap.servers'</b>: Kafka brokers to connect to[As per your karafka dashboard] </li>\n","  <li><b>'default.topic.config</b>:Offset to start reading from in the partition of a topic </li>\n","  <li><b>'security.protocol':</b> Security protocol to be used</li>\n","   <li><b>'sasl.mechanisms':</b> Authentication to be used </li>\n","</ol>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ee23ff06-aa49-411e-9d69-738b7062d0c5","showTitle":false,"title":""}},"outputs":[],"source":["consumer_conf = {\n","    'bootstrap.servers': CLOUDKARAFKA_BROKERS,\n","    'subscribe': CLOUDKARAFKA_TOPIC,\n","    'default.topic.config': {'auto.offset.reset': 'smallest'},\n","    'security.protocol': 'SASL_SSL',\n","    'sasl.mechanisms': 'SCRAM-SHA-256',\n","}"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"16947dc3-21c0-4ab7-ac90-b9a9f7c6ed2d","showTitle":false,"title":""}},"source":["#SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"15ed9d6c-1a3d-4004-9b68-0a7797f86718","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","spark = SparkSession\\\n","        .builder\\\n","        .appName(\"Kafka_Pyspark\")\\\n","        .getOrCreate()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3282909b-e071-44ec-a32b-2f69fe1dc503","showTitle":false,"title":""}},"source":["###Set sparkContext property for authentication"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"94f067aa-7112-4a2f-a54b-8951cfbe34f2","showTitle":false,"title":""}},"source":["###<p><b>For databricks environment :Add Kafka clients libraries to your environment</b>\n","  <br>Follow instructions from environment"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"48e60155-fde5-4dae-aeba-19ff4151121c","showTitle":false,"title":""}},"outputs":[],"source":["spark.sparkContext.setSystemProperty('java.security.auth.login.config', '/databricks/driver/kafka_conf.conf')"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"54ed78c6-ab18-4ea8-919d-824932869e32","showTitle":false,"title":""}},"source":["#Handling stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d6300335-7c7b-44dc-bda1-136b12fab88c","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.7)\r\n","Requirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.63.0)\r\n","Requirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.4)\r\n","Requirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2022.3.2)\r\n","Requirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n","\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\r\n","You should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.7)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.63.0)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.4)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2022.3.2)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.0.3 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6e1b48a2-5cff-4791-b022-7c7fff0b2cdf","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Out[102]: True"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nOut[102]: True","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fb0d15ad-362e-47d0-8c8a-5275a781e583","showTitle":false,"title":""}},"outputs":[],"source":["from nltk.corpus import stopwords\n","\n","swords  = sc.broadcast(list(set(stopwords.words('english'))))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2577b80e-1211-4de7-9186-afd78da426bb","showTitle":false,"title":""}},"outputs":[],"source":["def remove_stop(word):\n","    if len(word)<2:\n","        return False\n","    return  not (word in swords.value)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"58fce6d9-5e07-4ea7-a969-ad55da5a9f67","showTitle":false,"title":""}},"outputs":[],"source":["stopword_check = udf(lambda word : remove_stop(word))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d8dbc3a4-fae9-42ac-9a19-6592bf26649b","showTitle":false,"title":""}},"source":["#Create Spark Structure stream"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8312617e-3f71-4ec6-8db1-b6f94c7d6b7c","showTitle":false,"title":""}},"outputs":[],"source":["kafka_data = spark \\\n","        .readStream \\\n","        .format(\"kafka\") \\\n","        .options(**consumer_conf)\\\n","        .option(\"forceDeleteTempCheckpointLocation\", 'true')\\\n","        .load()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"24cfdee5-4ab0-41bc-8955-ddb9694c5856","showTitle":false,"title":""}},"source":["Decode producer messaged"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"084628b4-c510-435d-bda2-2bf603307850","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["root\n"," |-- key: binary (nullable = true)\n"," |-- value: binary (nullable = true)\n"," |-- topic: string (nullable = true)\n"," |-- partition: integer (nullable = true)\n"," |-- offset: long (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n"," |-- timestampType: integer (nullable = true)\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["from pyspark.sql.functions import col, decode, udf\n","from pyspark.sql.types import StringType\n","\n","decode_text = udf(lambda x: x.decode('unicode-escape'), StringType())\n","\n","#Confirm Schema\n","kafka_data.printSchema()\n","\n","\n","#Schema creation\n","from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n","schema = StructType([\n","    StructField(\"data\",StringType(), True)\n","])\n","\n","#convert byte obj to string\n","from pyspark.sql.functions import from_json, col\n","\n","df = kafka_data.withColumn(\"value\", col(\"value\").cast(\"String\"))\n","df = kafka_data.withColumn('value', decode_text('value'))\n","df = df.filter(df.partition==0)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3efd6ba5-b756-40f8-a6fb-293800d1f2ac","showTitle":false,"title":""}},"source":["Convert message text into words, each word in a separate row"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c495ca27-e138-4315-81bc-e84f6477d317","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import explode, lower, split\n","\n","df = df.select(explode(split(col('value'), pattern=\"\\\\W+\")).alias(\"Data\"), \"timestamp\").select(lower(col('Data')).alias('Data'), \"timestamp\")"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7c682495-4457-42fb-93e8-8dd622145880","showTitle":false,"title":""}},"source":["Remove stopwords from data"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6264b122-78b6-434f-b334-e1586cf322f5","showTitle":false,"title":""}},"outputs":[],"source":["df = df.select('Data', stopword_check(col('Data')).alias('filtered'), \"timestamp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"37922ddf-50bf-47bd-bdd4-bc25870fc4e6","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["root\n"," |-- Data: string (nullable = true)\n"," |-- timestamp: timestamp (nullable = true)\n"," |-- count: long (nullable = false)\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"root\n |-- Data: string (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- count: long (nullable = false)\n\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["df = df.filter(df.filtered==True).select('Data', \"timestamp\").withWatermark('timestamp', '0 seconds').groupBy(col('Data'), col('timestamp')).count()\n","df.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8f4d4cfe-ea6d-4c85-b719-8ef8e2ce7800","showTitle":false,"title":""}},"outputs":[],"source":["df = df.sort(col('count').desc())"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"56cdddb9-fd10-4471-a694-43a9c766b982","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["is spark streaming : True\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"is spark streaming : True\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["print(f\"is spark streaming : {df.isStreaming}\")"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f08297b9-0f47-41ad-b203-ae528d6ab265","showTitle":false,"title":""}},"source":["Stream Data"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"572be128-6ab9-45ba-b5f0-e376e4d19fef","showTitle":false,"title":""}},"outputs":[],"source":["query = df\\\n","    .writeStream\\\n","    .format(\"memory\")\\\n","    .queryName(\"counts\")\\\n","    .outputMode(\"complete\")\\\n","    .trigger(processingTime=\"10 seconds\")\\\n","    .start()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"82fda0e4-0f96-44d4-900e-1291a61ddc0a","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["+--------+-----+\n","|    Data|count|\n","+--------+-----+\n","|    upon|    2|\n","|  hurled|    2|\n","|clinging|    1|\n","|mountain|    1|\n","| drowned|    1|\n","+--------+-----+\n","only showing top 5 rows\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"+--------+-----+\n|    Data|count|\n+--------+-----+\n|    upon|    2|\n|  hurled|    2|\n|clinging|    1|\n|mountain|    1|\n| drowned|    1|\n+--------+-----+\nonly showing top 5 rows\n\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["spark.sql(\"SELECT * FROM counts\").show(5)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Kafka-Consumer","notebookOrigID":1558358774409844,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
